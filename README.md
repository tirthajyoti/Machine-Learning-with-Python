# Python Machine Learning Notebooks (Tutorial style)
---
### Dr. Tirthajyoti Sarkar, Fremont, CA ([Please feel free to add me on LinkedIn here](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7))
---
Essential codes/demo IPython notebooks for jump-starting machine learning/data science.

<img src="https://cookieegroup.com/wp-content/uploads/2018/10/2-1.png" width="450" height="300"/>

You can start with this article that I wrote in Heartbeat magazine (on Medium platform): 
### ["Some Essential Hacks and Tricks for Machine Learning with Python"](https://heartbeat.fritz.ai/some-essential-hacks-and-tricks-for-machine-learning-with-python-5478bc6593f2)

## Essential tutorial-type notebooks on Pandas and Numpy
Jupyter notebooks covering a wide range of functions and operations on the topics of NumPy, Pandans, Seaborn, matplotlib etc.
* **[Basics of Numpy array](https://github.com/tirthajyoti/PythonMachineLearning/blob/master/Pandas%20and%20Numpy/Basics%20of%20Numpy%20arrays.ipynb)**
* **[Basics of Pandas DataFrame](https://github.com/tirthajyoti/PythonMachineLearning/blob/master/Pandas%20and%20Numpy/Basics%20of%20Pandas%20DataFrame.ipynb)**
* **[Basics of Matplotlib and Descriptive Statistics](https://github.com/tirthajyoti/PythonMachineLearning/blob/master/Pandas%20and%20Numpy/Basics%20of%20Matplotlib%20and%20Descriptive%20Statistics.ipynb)**

## Tutorial-type notebooks covering regression, classification, clustering, dimensionality reduction, and some basic neural network algorithms

### Regression
* Simple linear regression with t-statistic generation
<img src="https://slideplayer.com/slide/6053182/20/images/10/Simple+Linear+Regression+Model.jpg" width="400" height="300"/>

* Multiple ways to perform linear regression in Python and their speed comparison ([check the article I wrote on freeCodeCamp](https://medium.freecodecamp.org/data-science-with-python-8-ways-to-do-linear-regression-and-measure-their-speed-b5577d75f8b))
* Multi-variate regression with regularization
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/L1_and_L2_balls.svg/300px-L1_and_L2_balls.svg.png"/>

* Polynomial regression using ***scikit-learn pipeline feature*** ([check the article I wrote on *Towards Data Science*](https://towardsdatascience.com/machine-learning-with-python-easy-and-robust-method-to-fit-nonlinear-data-19e8a1ddbd49))
* Decision trees and Random Forest regression (showing how the Random Forest works as a robust/regularized meta-estimator rejecting overfitting)

-----

### Classification
* Logistic regression/classification
<img src="https://qph.fs.quoracdn.net/main-qimg-914b29e777e78b44b67246b66a4d6d71"/>

* _k_-nearest neighbor classification
* Decision trees and Random Forest Classification
* Support vector machine classification (**[check the article I wrote in Towards Data Science on SVM and sorting algorithm](https://towardsdatascience.com/how-the-good-old-sorting-algorithm-helps-a-great-machine-learning-technique-9e744020254b))**

<img src="https://docs.opencv.org/2.4/_images/optimal-hyperplane.png"/>

* Naive Bayes classification

---

### Clustering
<img src="https://i.ytimg.com/vi/IJt62uaZR-M/maxresdefault.jpg" width="450" height="300"/>

* _K_-means clustering
* Affinity propagation (showing its time complexity and the effect of damping factor)
* Mean-shift technique (showing its time complexity and the effect of noise on cluster discovery)
* DBSCAN (showing how it can generically detect areas of high density irrespective of cluster shapes, which the k-means fails to do)
* Hierarchical clustering with Dendograms showing how to choose optimal number of clusters
<img src="https://www.researchgate.net/profile/Carsten_Walther/publication/273456906/figure/fig3/AS:294866065084419@1447312956501/Example-of-hierarchical-clustering-clusters-are-consecutively-merged-with-the-most.png" width="700" height="400"/>

---

### Dimensionality reduction
* Principal component analysis

<img src="https://i.ytimg.com/vi/QP43Iy-QQWY/maxresdefault.jpg" width="450" height="300"/>

---

### Deep Learning/Neural Network
* [Demo notebook to illustrate the superiority of deep neural network for complex nonlinear function approximation task](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Function%20Approximation%20by%20Neural%20Network/Polynomial%20regression%20-%20linear%20and%20neural%20network.ipynb)
* Step-by-step building of 1-hidden-layer and 2-hidden-layer dense network using basic TensorFlow methods

---

## Random data generation using symbolic expressions
* How to use [Sympy package](https://www.sympy.org/en/index.html) to generate random datasets using symbolic mathematical expressions.

Here is my article on Medium on this topic: [Random regression and classification problem generation with symbolic expression](https://towardsdatascience.com/random-regression-and-classification-problem-generation-with-symbolic-expression-a4e190e37b8d)
